{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIZrAUx57vsM"
   },
   "source": [
    "Practical 1: Sentiment Detection in Movie Reviews\n",
    "========================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4kXPMhyngZW"
   },
   "source": [
    "This practical concerns detecting sentiment in movie reviews. This is a typical NLP classification task.\n",
    "In [this file](https://gist.githubusercontent.com/bastings/d47423301cca214e3930061a5a75e177/raw/5113687382919e22b1f09ce71a8fecd1687a5760/reviews.json) (80MB) you will find 1000 positive and 1000 negative **movie reviews**.\n",
    "Each review is a **document** and consists of one or more sentences.\n",
    "\n",
    "To prepare yourself for this practical, you should\n",
    "have a look at a few of these texts to understand the difficulties of\n",
    "the task: how might one go about classifying the texts? You will write\n",
    "code that decides whether a movie review conveys positive or\n",
    "negative sentiment.\n",
    "\n",
    "Please make sure you have read the following paper:\n",
    "\n",
    ">   Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan\n",
    "(2002). \n",
    "[Thumbs up? Sentiment Classification using Machine Learning\n",
    "Techniques](https://dl.acm.org/citation.cfm?id=1118704). EMNLP.\n",
    "\n",
    "Bo Pang et al. introduced the movie review sentiment\n",
    "classification task, and the above paper was one of the first papers on\n",
    "the topic. The first version of your sentiment classifier will do\n",
    "something similar to Pang et al.'s system. If you have questions about it,\n",
    "you should resolve you doubts as soon as possible with your TA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cb7errgRASzZ"
   },
   "source": [
    "**Advice**\n",
    "\n",
    "Please read through the entire practical and familiarise\n",
    "yourself with all requirements before you start coding or otherwise\n",
    "solving the tasks. Writing clean and concise code can make the difference\n",
    "between solving the assignment in a matter of hours, and taking days to\n",
    "run all experiments.\n",
    "\n",
    "## Environment\n",
    "\n",
    "All code should be written in **Python 3**. \n",
    "This is the default in Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SaZnxptMJiD7",
    "outputId": "477e9631-3a03-4cbe-d138-e7859dfd8876"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.11\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYZyIF7lJnGn"
   },
   "source": [
    "If you want to run code on your own computer, then download this notebook through `File -> Download .ipynb`.\n",
    "The easiest way to\n",
    "install Python is through downloading\n",
    "[Anaconda](https://www.anaconda.com/download). \n",
    "After installation, you can start the notebook by typing `jupyter notebook filename.ipynb`.\n",
    "You can also use an IDE\n",
    "such as [PyCharm](https://www.jetbrains.com/pycharm/download/) to make\n",
    "coding and debugging easier. It is good practice to create a [virtual\n",
    "environment](https://docs.python.org/3/tutorial/venv.html) for this\n",
    "project, so that any Python packages don’t interfere with other\n",
    "projects. \n",
    " \n",
    "\n",
    "**Learning Python 3**\n",
    "\n",
    "If you are new to Python 3, you may want to check out a few of these resources:\n",
    "- https://learnxinyminutes.com/docs/python3/\n",
    "- https://www.learnpython.org/\n",
    "- https://docs.python.org/3/tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hok-BFu9lGoK"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "from subprocess import call\n",
    "from nltk import FreqDist\n",
    "from nltk.util import ngrams\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import sklearn as sk\n",
    "import pickle\n",
    "import json\n",
    "import typing as tg\n",
    "from collections import Counter\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "aEGmhtCHPZhU"
   },
   "outputs": [],
   "source": [
    "# whether to check if GPU is enabled\n",
    "CHECK_GPU = False\n",
    "# whether to mount google drive\n",
    "MOUNT_DRIVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eZOQWo43JmfP",
    "outputId": "35046a42-2875-4802-eee0-34de865ec541"
   },
   "outputs": [],
   "source": [
    "# checks\n",
    "if CHECK_GPU:\n",
    "  if not (int(os.environ[\"COLAB_GPU\"]) > 0):\n",
    "      raise ValueError(\"GPU Not enabled!\")\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except ModuleNotFoundError:\n",
    "  IN_COLAB = False\n",
    "if IN_COLAB and MOUNT_DRIVE:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive/')\n",
    "  os.chdir('/content/drive/MyDrive/Education/Masters/notebooks/nlp1/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXWyGHwE-ieQ"
   },
   "source": [
    "## Loading the data\n",
    "\n",
    "**Download the sentiment lexicon and the movie reviews dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lm-rakqtlMOT",
    "outputId": "dba73bbd-6a55-4733-f74c-1bc134bd2e42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘sent_lexicon’ already there; not retrieving.\n",
      "\n",
      "File ‘reviews.json’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download sentiment lexicon\n",
    "!wget -nc https://gist.githubusercontent.com/bastings/d6f99dcb6c82231b94b013031356ba05/raw/f80a0281eba8621b122012c89c8b5e2200b39fd6/sent_lexicon\n",
    "# download review data\n",
    "!wget -nc https://gist.githubusercontent.com/bastings/d47423301cca214e3930061a5a75e177/raw/5113687382919e22b1f09ce71a8fecd1687a5760/reviews.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkPwuHp5LSuQ"
   },
   "source": [
    "**Load the movie reviews.**\n",
    "\n",
    "Each word in a review comes with its part-of-speech tag. For documentation on POS-tags, see https://catalog.ldc.upenn.edu/docs/LDC99T42/tagguid1.pdf.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "careEKj-mRpl",
    "outputId": "259f53b3-b8b1-446d-90b0-195802ba6ad8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of reviews: 2000 \n",
      "\n",
      "0 NEG 29\n",
      "Two/CD teen/JJ couples/NNS go/VBP to/TO a/DT church/NN party/NN ,/, drink/NN and/CC then/RB drive/NN ./.\n",
      "1 NEG 11\n",
      "Damn/JJ that/IN Y2K/CD bug/NN ./.\n",
      "2 NEG 24\n",
      "It/PRP is/VBZ movies/NNS like/IN these/DT that/WDT make/VBP a/DT jaded/JJ movie/NN viewer/NN thankful/JJ for/IN the/DT invention/NN of/IN the/DT Timex/NNP IndiGlo/NNP watch/NN ./.\n",
      "3 NEG 19\n",
      "QUEST/NN FOR/IN CAMELOT/NNP ``/`` Quest/NNP for/IN Camelot/NNP ''/'' is/VBZ Warner/NNP Bros./NNP '/POS first/JJ feature-length/JJ ,/, fully-animated/JJ attempt/NN to/TO steal/VB clout/NN from/IN Disney/NNP 's/POS cartoon/NN empire/NN ,/, but/CC the/DT mouse/NN has/VBZ no/DT reason/NN to/TO be/VB worried/VBN ./.\n",
      "4 NEG 38\n",
      "Synopsis/NNPS :/: A/DT mentally/RB unstable/JJ man/NN undergoing/VBG psychotherapy/NN saves/VBZ a/DT boy/NN from/IN a/DT potentially/RB fatal/JJ accident/NN and/CC then/RB falls/VBZ in/IN love/NN with/IN the/DT boy/NN 's/POS mother/NN ,/, a/DT fledgling/NN restauranteur/NN ./.\n",
      "\n",
      "Number of word types: 47743\n",
      "Number of word tokens: 1512359\n",
      "\n",
      "Most common tokens:\n",
      "         , :    77842\n",
      "       the :    75948\n",
      "         . :    59027\n",
      "         a :    37583\n",
      "       and :    35235\n",
      "        of :    33864\n",
      "        to :    31601\n",
      "        is :    25972\n",
      "        in :    21563\n",
      "        's :    18043\n",
      "        it :    15904\n",
      "      that :    15820\n",
      "     -rrb- :    11768\n",
      "     -lrb- :    11670\n",
      "        as :    11312\n",
      "      with :    10739\n",
      "       for :     9816\n",
      "       his :     9542\n",
      "      this :     9497\n",
      "      film :     9404\n"
     ]
    }
   ],
   "source": [
    "# file structure:\n",
    "# [\n",
    "#  {\"cv\": integer, \"sentiment\": str, \"content\": list} \n",
    "#  {\"cv\": integer, \"sentiment\": str, \"content\": list} \n",
    "#   ..\n",
    "# ]\n",
    "# where `content` is a list of sentences, \n",
    "# with a sentence being a list of (token, pos_tag) pairs.\n",
    "\n",
    "# true_sent = []\n",
    "\n",
    "with open(\"reviews.json\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "  reviews = json.load(f)\n",
    "  \n",
    "print(\"Total number of reviews:\", len(reviews), '\\n')\n",
    "\n",
    "def print_sentence_with_pos(s):\n",
    "  print(\" \".join(\"%s/%s\" % (token, pos_tag) for token, pos_tag in s))\n",
    "\n",
    "for i, r in enumerate(reviews):\n",
    "  print(r[\"cv\"], r[\"sentiment\"], len(r[\"content\"]))  # cv, sentiment, num sents\n",
    "  # true_sent.append(r[\"sentiment\"])\n",
    "  print_sentence_with_pos(r[\"content\"][0])\n",
    "  if i == 4: \n",
    "    break\n",
    "    \n",
    "c = Counter()\n",
    "for review in reviews:\n",
    "  for sentence in review[\"content\"]:\n",
    "    for token, pos_tag in sentence:\n",
    "      c[token.lower()] += 1\n",
    "      \n",
    "print(\"\\nNumber of word types:\", len(c))\n",
    "print(\"Number of word tokens:\", sum(c.values()))\n",
    "\n",
    "print(\"\\nMost common tokens:\")\n",
    "for token, count in c.most_common(20):\n",
    "  print(\"%10s : %8d\" % (token, count))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6PWaEoh8B34"
   },
   "source": [
    "# Lexicon-based approach (3.5pts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsTSMb6ma4E8"
   },
   "source": [
    "A traditional approach to classify documents according to their sentiment is the lexicon-based approach. To implement this approach, you need a **sentiment lexicon**, i.e., a list of words annotated with a sentiment label (e.g., positive and negative, or a score from 0 to 5).\n",
    "\n",
    "In this practical, you will use the sentiment\n",
    "lexicon released by Wilson et al. (2005).\n",
    "\n",
    "> Theresa Wilson, Janyce Wiebe, and Paul Hoffmann\n",
    "(2005). [Recognizing Contextual Polarity in Phrase-Level Sentiment\n",
    "Analysis](http://www.aclweb.org/anthology/H/H05/H05-1044.pdf). HLT-EMNLP.\n",
    "\n",
    "Pay attention to all the information available in the sentiment lexicon. The field *word1* contains the lemma, *priorpolarity* contains the sentiment label (positive, negative, both, or neutral), *type* gives you the magnitude of the word's sentiment (strong or weak), and *pos1* gives you the part-of-speech tag of the lemma. Some lemmas can have multiple part-of-speech tags and thus multiple entries in the lexicon. The path of the lexicon file is `\"sent_lexicon\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ogq0Eq2hQglh",
    "outputId": "ff45d866-1d5f-4d95-93f8-e393c2d07556"
   },
   "outputs": [],
   "source": [
    "pos = []\n",
    "strengths = []\n",
    "with open(\"sent_lexicon\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    line_cnt = 0\n",
    "    for line in f:\n",
    "        metadata = line.strip()\n",
    "        # print(metadata)\n",
    "        w_type, w_len, word, word_pos, word_stem, polarity = metadata.split()\n",
    "        pos.append(word_pos[5:])\n",
    "        strengths.append(w_type[5:])\n",
    "        line_cnt += 1\n",
    "        # if line_cnt > 4:\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'strongsubj', 'weaksubj'}\n",
      "{'adj', 'adverb', 'verb', 'noun', 'anypos'}\n"
     ]
    }
   ],
   "source": [
    "print(set(strengths))\n",
    "print(set(pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mml4nOtIUBhn"
   },
   "source": [
    "Lexica such as this can be used to solve\n",
    "the classification task without using Machine Learning. For example, one might look up every word $w_1 ... w_n$ in a document, and compute a **binary score**\n",
    "$S_{binary}$ by counting how many words have a positive or a\n",
    "negative label in the sentiment lexicon $SLex$.\n",
    "\n",
    "$$S_{binary}(w_1 w_2 ... w_n) = \\sum_{i = 1}^{n}\\text{sign}(SLex\\big[w_i\\big])$$\n",
    "\n",
    "where $\\text{sign}(SLex\\big[w_i\\big])$ refers to the polarity of $w_i$.\n",
    "\n",
    "**Threshold.** On average, there are more positive than negative words per review (~7.13 more positive than negative per review) to take this bias into account you should use a threshold of **8** (roughly the bias itself) to make it harder to classify as positive.\n",
    "\n",
    "$$\n",
    "\\text{classify}(S_{binary}(w_1 w_2 ... w_n)) = \\bigg\\{\\begin{array}{ll}\n",
    "        \\text{positive} & \\text{if } S_{binary}(w_1w_2...w_n) > threshold\\\\\n",
    "        \\text{negative} & \\text{otherwise}\n",
    "        \\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOFnMvbeeZrc"
   },
   "source": [
    "#### (Q1.1) Implement this approach and report its classification accuracy. (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ED2aTEYutW1-"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def compute_weighted_score(word_list: tg.List[str], lexicon: tg.Dict) -> int:\n",
    "    \"\"\"\n",
    "    Computes the weighted score by summing the strength of each word in the\n",
    "    word list\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    word_list : tg.List[str]\n",
    "        The list of words to be scored.\n",
    "    lexicon : tg.Dict\n",
    "        The lexicon to be used for scoring\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The weighted score.\n",
    "    \"\"\"\n",
    "    weighted_pol_arr = np.array(\n",
    "        [\n",
    "            lexicon[word][\"strength\"] * lexicon[word][\"polarity\"]\n",
    "            for word in word_list\n",
    "            if word in lexicon\n",
    "        ]\n",
    "    )\n",
    "    return weighted_pol_arr.sum().astype(int)\n",
    "\n",
    "\n",
    "def compute_bin_score(word_list: tg.List[str], lexicon: tg.Dict):\n",
    "    \"\"\"\n",
    "    Computes the binary score by counting how many words have a positive or a\n",
    "    negative label in the sentiment lexicon\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    word_list : tg.List[str]\n",
    "        The list of words to be scored.\n",
    "    lexicon : tg.Dict\n",
    "        The lexicon to be used for scoring\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The binary score.\n",
    "    \"\"\"\n",
    "    polarity_arr = np.array(\n",
    "        [lexicon[word][\"polarity\"] for word in word_list if word in lexicon]\n",
    "    )\n",
    "    return polarity_arr.sum().astype(int)\n",
    "\n",
    "\n",
    "def classify_document(\n",
    "    document: tg.Dict,\n",
    "    lexicon: tg.Dict,\n",
    "    mode: str = \"unweighted\",\n",
    "    thresh: float = 8.0,\n",
    "    thresh_kind: str = \"absolute\",\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Classifies a document using a lexicon approach as either positive or negative.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    document : dict\n",
    "        The document to be classified.\n",
    "        {\"cv\": integer, \"sentiment\": str, \"content\": list of (word, pos)}\n",
    "    lexicon : dict\n",
    "        The lexicon to be used for scoring\n",
    "    mode : str\n",
    "        The mode of classification.\n",
    "    thresh : float, default 8.0\n",
    "        The threshold to be used for classification.\n",
    "    thresh_kind : str, default \"absolute\"\n",
    "        The kind of threshold to be used for classification.\n",
    "        \"absolute\" for absolute threshold\n",
    "        \"density\" for density threshold\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        1 if the document is positive, -1 if negative.\n",
    "    \"\"\"\n",
    "    assert mode in [\n",
    "        \"unweighted\",\n",
    "        \"weighted\",\n",
    "    ], \"`mode` must be either 'unweighted' or 'weighted'\"\n",
    "    # flatten document\n",
    "    data = [\n",
    "        word.lower()\n",
    "        for sentence in document[\"content\"]\n",
    "        for word, _pos in sentence\n",
    "        if word.lower() in lexicon and lexicon[word.lower()][\"polarity\"] in [1, -1]\n",
    "    ]\n",
    "    if mode == \"unweighted\":\n",
    "        score_func = compute_bin_score\n",
    "    else:\n",
    "        score_func = compute_weighted_score\n",
    "    score = score_func(data, lexicon)\n",
    "    if thresh_kind == \"density\":\n",
    "        thresh = np.ceil(thresh * len(data))\n",
    "    # finally, we can classify\n",
    "    return 1 if score > thresh else -1\n",
    "\n",
    "\n",
    "def build_lexicon(file_path: str) -> tg.Dict:\n",
    "    \"\"\"\n",
    "    Builds a lexicon from a file.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    file_path : str The path to the file.\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    A dictionary containing the lexicon data\n",
    "    \"\"\"\n",
    "    lexicon: tg.Dict = {}\n",
    "    with open(file_path, \"r\") as f:\n",
    "        # parse file line by line\n",
    "        for line in f:\n",
    "            strength, length, word, pos, stemmed, polarity = line.split()\n",
    "            # we ignore duplicate words, keep only most recent\n",
    "            lexicon[word[6:].lower()] = {\n",
    "                \"strength\": 2 if strength[5:] == \"strongsubj\" else 1,\n",
    "                \"length\": int(length[4:]),\n",
    "                \"pos\": pos[5:],\n",
    "                \"stemmed\": stemmed[9:],\n",
    "                \"polarity\": 1\n",
    "                if polarity[14:] == \"positive\"\n",
    "                else -1\n",
    "                if polarity[14:] == \"negative\"\n",
    "                else 0,\n",
    "            }\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if name == main (lol)\n",
    "lexicon = build_lexicon(\"sent_lexicon\")\n",
    "# pred and labels\n",
    "y_pred = np.array([classify_document(review, lexicon) for review in reviews])\n",
    "y_true = np.array([1 if review[\"sentiment\"] == \"POS\" else -1 for review in reviews])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "iy528EUTphz5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "# token_results should be a list of binary indicators; for example [1, 0, 1, ...] \n",
    "# where 1 indicates a correct classification and 0 an incorrect classification.\n",
    "token_results = (y_pred == y_true).astype(int)\n",
    "token_accuracy = token_results.sum()/len(token_results)\n",
    "print(\"Accuracy: %0.2f\" % token_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Twox0s_3eS0V"
   },
   "source": [
    "As the sentiment lexicon also has information about the **magnitude** of\n",
    "sentiment (e.g., *“excellent\"* has the same sentiment _polarity_ as *“good\"* but it has a higher magnitude), we can take a more fine-grained approach by adding up all\n",
    "sentiment scores, and deciding the polarity of the movie review using\n",
    "the sign of the weighted score $S_{weighted}$.\n",
    "\n",
    "$$S_{weighted}(w_1w_2...w_n) = \\sum_{i = 1}^{n}SLex\\big[w_i\\big]$$\n",
    "\n",
    "\n",
    "Make sure you define an appropriate threshold for this approach.\n",
    "\n",
    "#### (Q1.2) Now incorporate magnitude information and report the classification accuracy. Don't forget to use the threshold. (1pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qG3hUDnPtkhS"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def determine_threshold(\n",
    "    documents: tg.List[tg.Dict],\n",
    "    lexicon: tg.Dict,\n",
    "    mode: str = \"unweighted\",\n",
    "    kind: str = \"absolute\",\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Determines the threshold to be used for classification, based on the\n",
    "    average imbalance of positive to negative words in a document.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    documents : tg.List[dict]\n",
    "        The list of documents to be used for threshold determination.\n",
    "    lexicon : dict\n",
    "        The lexicon to be used for word polarity determination.\n",
    "    mode : str, default \"unweighted\"\n",
    "        The mode of classification.\n",
    "    kind : str, default \"absolute\"\n",
    "        The kind of threshold to be used for classification.\n",
    "        \"absolute\" for absolute threshold\n",
    "        \"density\" for density threshold\n",
    "    \"\"\"\n",
    "    diffs = np.zeros(len(documents), dtype=float)\n",
    "    lens = diffs.copy()\n",
    "    for i, doc in enumerate(documents):\n",
    "        n_positives = 0\n",
    "        n_negatives = 0\n",
    "        for sentence in doc[\"content\"]:\n",
    "            for word, _pos in sentence:\n",
    "                word = word.lower()\n",
    "                if word in lexicon:\n",
    "                    lens[i] += 1\n",
    "                    if mode == \"unweighted\":\n",
    "                        weight = 1\n",
    "                    else:\n",
    "                        weight = lexicon[word][\"strength\"]\n",
    "                    if lexicon[word][\"polarity\"] == 1:\n",
    "                        n_positives += 1 * weight\n",
    "                    elif lexicon[word][\"polarity\"] == -1:\n",
    "                        n_negatives += 1 * weight\n",
    "        diffs[i] = n_positives - n_negatives\n",
    "    if kind == \"density\":\n",
    "        return np.mean(diffs / lens)\n",
    "    else:\n",
    "        return np.ceil(np.mean(diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_thresh = determine_threshold(reviews, lexicon, \"weighted\")\n",
    "\n",
    "y_pred = np.array(\n",
    "    [classify_document(review, lexicon, \"weighted\", new_thresh) for review in reviews]\n",
    ")\n",
    "y_true = np.array([1 if review[\"sentiment\"] == \"POS\" else -1 for review in reviews])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "9vVk7CvDpyka"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.70\n"
     ]
    }
   ],
   "source": [
    "magnitude_results = (y_pred == y_true).astype(int)\n",
    "magnitude_accuracy = magnitude_results.sum()/len(magnitude_results)\n",
    "print(\"Accuracy: %0.2f\" % magnitude_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9SHoGPfsAHV"
   },
   "source": [
    "#### (Q.1.4) Make a barplot of the two results (0.5pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "8LgBcYcXsEk3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.barh(\n",
    "    [\"binary\", \"weighted\"],\n",
    "    [token_accuracy, magnitude_accuracy],\n",
    "    color=[\"darkblue\", \"black\"],\n",
    ")\n",
    "plt.xlabel(\"accuracy\")\n",
    "plt.title(\"Fig 1: Accuracy of Lexicon Classifier using binary and weighted scoring functions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNhS8OCVxMHd"
   },
   "source": [
    "#### (Q1.3) A better threshold (1pt)\n",
    "Above we have defined a threshold to account for an inherent bias in the dataset: there are more positive than negative words per review.\n",
    "However, that threshold does not take into account *document length*. Explain why this is a problem and implement an alternative way to compute the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xo7gk1I-omLI"
   },
   "source": [
    "---\n",
    "\n",
    "Not taking into account document length is problematic because it unfairly punishes shorter documents. For instance, a very short positive review with less positive words than the threshold will be incorrectly classified as negative. A simple solution to this is computing the score dynamically for each document based on its length, adjusting the threshold across all documents based on the average document length. \n",
    "\n",
    "The code below shows an implementation of this. Note that we also adjust the original threshold to an empirically-determined value (12, instead of 11).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average amount of words:  756.1795\n"
     ]
    }
   ],
   "source": [
    "# determining the average review length\n",
    "ave_rev_len = sum([sum([len(s) for s in r[\"content\"]]) for r in reviews]) / len(reviews)\n",
    "print(\"Average amount of words: \", ave_rev_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.70\n"
     ]
    }
   ],
   "source": [
    "def Sbinary_thres(ws):\n",
    "    sum = 0\n",
    "    for w in ws:\n",
    "        if w in lexicon:\n",
    "            sum += lexicon[w][\"strength\"]*lexicon[w][\"polarity\"]\n",
    "    return sum / len(ws)\n",
    "\n",
    "def classify_thres(ws, threshold=12/ave_rev_len):\n",
    "    if Sbinary_thres(ws) > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def test_classifier_thres(reviews):\n",
    "    results = []\n",
    "    for i, r in enumerate(reviews):    \n",
    "        words = []\n",
    "        for sentence in r[\"content\"]:\n",
    "            for w in sentence:\n",
    "                words.append(w[0].lower())\n",
    "\n",
    "        sentiment = 1\n",
    "        if r[\"sentiment\"] == \"NEG\":\n",
    "            sentiment = -1\n",
    "        prediction = classify_thres(words)\n",
    "\n",
    "        results.append(sentiment == prediction)\n",
    "    \n",
    "    return results\n",
    "\n",
    "thres_results = test_classifier_thres(reviews)\n",
    "thres_accuracy = sum(thres_results) / len(reviews)\n",
    "print(\"Accuracy: %0.2f\" % thres_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LibV4nR89BXb"
   },
   "source": [
    "# Naive Bayes (9.5pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnF9adQnuwia"
   },
   "source": [
    "\n",
    "Your second task is to program a simple Machine Learning approach that operates\n",
    "on a simple Bag-of-Words (BoW) representation of the text data, as\n",
    "described by Pang et al. (2002). In this approach, the only features we\n",
    "will consider are the words in the text themselves, without bringing in\n",
    "external sources of information. The BoW model is a popular way of\n",
    "representing texts as vectors, making it\n",
    "easy to apply classical Machine Learning algorithms on NLP tasks.\n",
    "However, the BoW representation is also very crude, since it discards\n",
    "all information related to word order and grammatical structure in the\n",
    "original text—as the name suggests.\n",
    "\n",
    "## Writing your own classifier (4pts)\n",
    "\n",
    "Write your own code to implement the Naive Bayes (NB) classifier. As\n",
    "a reminder, the Naive Bayes classifier works according to the following\n",
    "equation:\n",
    "$$\\hat{c} = \\operatorname*{arg\\,max}_{c \\in C} P(c|\\bar{f}) = \\operatorname*{arg\\,max}_{c \\in C} P(c)\\prod^n_{i=1} P(f_i|c)$$\n",
    "where $C = \\{ \\text{POS}, \\text{NEG} \\}$ is the set of possible classes,\n",
    "$\\hat{c} \\in C$ is the most probable class, and $\\bar{f}$ is the feature\n",
    "vector. Remember that we use the log of these probabilities when making\n",
    "a prediction:\n",
    "$$\\hat{c} = \\operatorname*{arg\\,max}_{c \\in C} \\Big\\{\\log P(c) + \\sum^n_{i=1} \\log P(f_i|c)\\Big\\}$$\n",
    "\n",
    "You can find more details about Naive Bayes in [Jurafsky &\n",
    "Martin](https://web.stanford.edu/~jurafsky/slp3/). You can also look at\n",
    "this helpful\n",
    "[pseudo-code](https://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html).\n",
    "\n",
    "*Note: this section and the next aim to put you in a position to replicate\n",
    "    Pang et al.'s Naive Bayes results. However, your numerical results\n",
    "    will differ from theirs, as they used different data.*\n",
    "\n",
    "**You must write the Naive Bayes training and prediction code from\n",
    "scratch.** You will not be given credit for using off-the-shelf Machine\n",
    "Learning libraries.\n",
    "\n",
    "The data contains the text of the reviews, where each document consists\n",
    "of the sentences in the review, the sentiment of the review and an index\n",
    "(cv) that you will later use for cross-validation. The\n",
    "text has already been tokenised and POS-tagged for you. Your algorithm\n",
    "should read in the text, **lowercase it**, store the words and their\n",
    "frequencies in an appropriate data structure that allows for easy\n",
    "computation of the probabilities used in the Naive Bayes algorithm, and\n",
    "then make predictions for new instances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEpyQSBSkb33"
   },
   "source": [
    "#### (Q2.1) Unseen words (1pt)\n",
    "The presence of words in the test dataset that\n",
    "have not been seen during training can cause probabilities in the Naive Bayes classifier to equal $0$.\n",
    "These can be words which are unseen in both positive and negative training reviews (case 1), but also words which are seen in reviews _of only one sentiment class_ in the training dataset (case 2). In both cases, **you should skip these words for both classes**.  What would be the problem instead with skipping words only for one class in case 2? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BanFiYYnoxDW"
   },
   "source": [
    "---\n",
    "\n",
    "To compute the score (log posterior), we need the per-class log-prior and per-word-in-class log-likelihood. The latter is computed as the log of the count of the given word for that class over the total count of words in that class.\n",
    "\n",
    "If a given word in the vocabulary did not appear when training a specific class, the count for that word in that class will be 0. This results in an estimated likelihood of 0 for that word, which is unreasonable. More importantly however, this makes it impossible to find the log likelihood for that word, since the log of 0 is undefined. The problem traverses upwards in our implementation causing our estimated score to be incorrect. \n",
    "\n",
    "Note, this remains problematic even without considering log-probabilities: a probability of 0 in our NB likelihood product would cause the entire likelihood for a given document to vanish. \n",
    "\n",
    "This is why our vocabulary needs to consist of words that appear across both classes at least once in the training when we are not smoothing.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsZRhaI3WvzC"
   },
   "source": [
    "#### (Q2.2) Train your classifier on (positive and negative) reviews with cv-value 000-899, and test it on the remaining (positive and negative) reviews cv900–cv999.  Report results using classification accuracy as your evaluation metric. Your  features are the word vocabulary. The value of a feature is the count of that feature (word) in the document. (2pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "G7zaJYGFvIJ3"
   },
   "outputs": [],
   "source": [
    "SENT_MAP = {\n",
    "    \"POS\": 0,\n",
    "    \"NEG\": 1,\n",
    "}\n",
    "\n",
    "\n",
    "def preprocess_reviews(\n",
    "    reviews: tg.List[tg.Dict],\n",
    "    stem: bool = False,\n",
    "    bigrams: bool = False,\n",
    "    trigrams: bool = False,\n",
    "    cached: bool = False,\n",
    ") -> tg.List[tg.Dict]:\n",
    "    \"\"\"\n",
    "    Preprocesses the reviews with lower-casing or stemming\n",
    "    and/or bigram and trigram calculation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    reviews : tg.List[Dict]\n",
    "        the reviews to preprocess\n",
    "    stem : bool, default False\n",
    "        Whether to stem the reviews, if False, simply lower-cases\n",
    "    bigram : bool, default False\n",
    "        Whether to calculate bigrams\n",
    "    trigrams : bool, default False\n",
    "        Whether to calculate bigrams _and_ trigrams\n",
    "    cached : bool, default False\n",
    "        Whether the passed `reviews` are already lower-cased/stemmed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tg.List[Dict]\n",
    "        the preprocessed reviews\n",
    "    \"\"\"\n",
    "    if not cached:\n",
    "        if stem:\n",
    "            print(\"Stemming requested; stemming...\")\n",
    "            stemmer = PorterStemmer()\n",
    "            new_reviews = [\n",
    "                {\n",
    "                    \"cv\": review[\"cv\"],\n",
    "                    \"sentiment\": review[\"sentiment\"],\n",
    "                    \"content\": [\n",
    "                        [(stemmer.stem(word), pos) for word, pos in sentence]\n",
    "                        for sentence in review[\"content\"]\n",
    "                    ],\n",
    "                }\n",
    "                for review in reviews\n",
    "            ]\n",
    "            print(\"Stemming complete.\")\n",
    "        else:\n",
    "            new_reviews = [\n",
    "                {\n",
    "                    \"cv\": review[\"cv\"],\n",
    "                    \"sentiment\": review[\"sentiment\"],\n",
    "                    \"content\": [\n",
    "                        [(word.lower(), pos) for word, pos in sentence]\n",
    "                        for sentence in review[\"content\"]\n",
    "                    ],\n",
    "                }\n",
    "                for review in reviews\n",
    "            ]\n",
    "    else:\n",
    "        new_reviews = copy.deepcopy(reviews)\n",
    "    if bigrams or trigrams:\n",
    "        print(\"Computing ngrams...\")\n",
    "        for review in new_reviews:\n",
    "            review_words = [\n",
    "                word for sentence in review[\"content\"] for word, _pos in sentence\n",
    "            ]\n",
    "            review_bigrams = list(ngrams(review_words, 2))\n",
    "            bigram_pos = [\"bigram\" for bigram in review_bigrams]\n",
    "            review[\"content\"].append(list(zip(review_bigrams, bigram_pos)))\n",
    "            if trigrams:\n",
    "                review_trigrams = list(ngrams(review_words, 3))\n",
    "                trigram_pos = [\"trigram\" for trigram in review_trigrams]\n",
    "                review[\"content\"].append(list(zip(review_trigrams, trigram_pos)))\n",
    "        print(\"Done.\")\n",
    "    return new_reviews\n",
    "\n",
    "\n",
    "def extract_vocab(\n",
    "    documents: tg.List[tg.Dict], use_pos: bool = False, only_open: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Extracts the vocabulary from the documents,\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    documents : tg.List[Dict]\n",
    "    use_pos : bool, default False\n",
    "        Whether to use the word+POS as vocab keys\n",
    "    only_open : bool, default False\n",
    "        Whether to only include open-class POS-tagged words,\n",
    "        ignored if `use_pos` is False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        The vocabulary\n",
    "    \"\"\"\n",
    "    vocab = {}\n",
    "    for doc in documents:\n",
    "        for sentence in doc[\"content\"]:\n",
    "            for token, pos in sentence:\n",
    "                if use_pos:\n",
    "                    key = (token, pos)\n",
    "                    if only_open:\n",
    "                        if pos not in POS_MAP:\n",
    "                            # skip this token\n",
    "                            continue\n",
    "                else:\n",
    "                    key = token\n",
    "                if key not in vocab:\n",
    "                    vocab[key] = {\"POS\": 0, \"NEG\": 0}\n",
    "                if doc[\"sentiment\"] == \"POS\":\n",
    "                    vocab[key][\"POS\"] += 1\n",
    "                elif doc[\"sentiment\"] == \"NEG\":\n",
    "                    vocab[key][\"NEG\"] += 1\n",
    "    return vocab\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_nb(\n",
    "    classes: tg.Tuple[str, ...],\n",
    "    documents: tg.List[tg.Dict],\n",
    "    alpha: float = 0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains a Naive Bayes model\n",
    "    Parameters\n",
    "    ----------\n",
    "    classes : tg.Tuple[str, ...]\n",
    "        the classes that the model should predict\n",
    "    documents : tg.List[Dict]\n",
    "        the documents on which to train on\n",
    "    alpha : float\n",
    "        smoothing parameter, which is added to word counts.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    vocab : tg.Dict\n",
    "        the computed vocabulary for the input documents\n",
    "    logprior : np.ndarray\n",
    "        (n_classes, ) array of log priors\n",
    "    loglikelihood : tg.List[tg.Dict]\n",
    "        (n_classes, ) array of dictionary containing loglikelihood of each word\n",
    "    \"\"\"\n",
    "    vocab: tg.Dict = extract_vocab(documents)\n",
    "    if alpha == 0:\n",
    "        # filter vocab if we are not applying smoothing\n",
    "        vocab = {k: v for (k, v) in vocab.items() if v[\"POS\"] > 0 and v[\"NEG\"] > 0}\n",
    "\n",
    "    n_docs = len(documents)\n",
    "    logprior = np.zeros(len(classes))\n",
    "    loglikelihood: tg.List[tg.Dict] = [{} for _ in range(len(classes))]\n",
    "    for c, clx in enumerate(classes):\n",
    "        clx_docs = [doc for doc in documents if doc[\"sentiment\"] == clx]\n",
    "        n_docs_clx = len(clx_docs)\n",
    "        logprior[c] = np.log(n_docs_clx / n_docs)\n",
    "        # compute sum of word counts, which we'll use to compute loglikelihood (denom)\n",
    "        word_counts_sum = (np.array([vocab[word][clx] for word in vocab]) + alpha).sum()\n",
    "        for word in vocab:\n",
    "            loglikelihood[c][word] = np.log(\n",
    "                (vocab[word][clx] + alpha) / (word_counts_sum)\n",
    "            )\n",
    "    return vocab, logprior, loglikelihood\n",
    "\n",
    "\n",
    "def nb_predict(\n",
    "    classes: tg.Tuple[str, ...],\n",
    "    vocab: tg.Dict,\n",
    "    logprior: np.ndarray,\n",
    "    loglikelihood: tg.List[tg.Dict],\n",
    "    doc: tg.Dict,\n",
    "):\n",
    "    \"\"\"\n",
    "    Predicts the sentiment of a document\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    classes : tg.Tuple[str, ...]\n",
    "    vocab : tg.Dict\n",
    "    prior : np.ndarray\n",
    "    loglikelihood : tg.List[tg.Dict]\n",
    "    doc : tg.Dict\n",
    "        the document to classify\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The index of the predicted class\n",
    "    \"\"\"\n",
    "    doc_text = [\n",
    "        token\n",
    "        for sentence in doc[\"content\"]\n",
    "        for token, _pos in sentence\n",
    "        if token in vocab\n",
    "    ]\n",
    "    score: np.ndarray = np.zeros(len(classes), dtype=float)\n",
    "    for c, clx in enumerate(classes):\n",
    "        score[c] = logprior[c]\n",
    "        for token in doc_text:\n",
    "            if token in vocab:\n",
    "                score[c] += loglikelihood[c][token]\n",
    "\n",
    "    return np.argmax(score)\n",
    "\n",
    "\n",
    "def train_eval_nb(\n",
    "    train_data: tg.List[tg.Dict], test_data: tg.List[tg.Dict], alpha: float = 0\n",
    ") -> tg.Tuple[float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Trains and evaluates a Naive Bayes model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data : tg.List[Dict]\n",
    "        the training data\n",
    "    test_data : tg.List[Dict]\n",
    "    alpha : float, default 0\n",
    "        smoothing parameter, which is added to word counts.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    metrics : tuple of floats\n",
    "        tuple of accuracy, precision, recall and vocab size\n",
    "    \"\"\"\n",
    "    vocab, logprior, loglikelihood = train_nb((\"POS\", \"NEG\"), train_data, alpha)\n",
    "    y_pred = np.array(\n",
    "        [\n",
    "            nb_predict((\"POS\", \"NEG\"), vocab, logprior, loglikelihood, doc)\n",
    "            for doc in test_data\n",
    "        ]\n",
    "    )\n",
    "    y_true = np.array([SENT_MAP[doc[\"sentiment\"]] for doc in test_data])\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    vocab_size = len(vocab.keys())\n",
    "\n",
    "    return accuracy, precision, recall, vocab_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.835\n"
     ]
    }
   ],
   "source": [
    "lower_case_reviews = preprocess_reviews(reviews)\n",
    "\n",
    "train_idxs = range(0, 900)\n",
    "test_idxs = range(900, 1000)\n",
    "train_reviews = [review for review in lower_case_reviews if review[\"cv\"] in train_idxs]\n",
    "test_reviews = [review for review in lower_case_reviews if review[\"cv\"] in test_idxs]\n",
    "\n",
    "\n",
    "accuracy, precision, recall, vocab_size = train_eval_nb(train_reviews, test_reviews)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0INK-PBoM6CB"
   },
   "source": [
    "#### (Q2.3) Would you consider accuracy to also be a good way to evaluate your classifier in a situation where 90% of your data instances are of positive movie reviews? (1pt)\n",
    "\n",
    "Simulate this scenario by keeping the positive reviews\n",
    "data unchanged, but only using negative reviews cv000–cv089 for\n",
    "training, and cv900–cv909 for testing. Calculate the classification\n",
    "accuracy, and explain what changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFbcsYlipBAw"
   },
   "source": [
    "---\n",
    "\n",
    "I would not consider accuracy to be a good way to evaluate our classifier in this situation. This is because in such a case, our dataset is strongly unbalanced towards one class, the positive one. The result is that our model will be incorrectly biased (and in a sense rewarded) for simply learning to predict the majority class regardless of the input. In a way, it is overfitting to a certain class. Because the majority of the input will be of this class, most of the model's predictions will be correct, increasing accuracy and artificially obtaining \"good\" results.\n",
    "\n",
    "While this may be fine for a problem where false positives are not a concern, it becomes problematic in problems sensitive to type I errors. This is noticed below where our accuracy increases when using an unbalanced dataset. Other metrics, such as precision and recall, are better suited for classification problems.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "GWDkt5ZrrFGp"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def split_data(\n",
    "    data: tg.List[tg.Dict],\n",
    "    pos_start_stop: tg.Tuple[tg.Tuple[int, int], tg.Tuple[int, int]],\n",
    "    neg_start_stop: tg.Optional[\n",
    "        tg.Tuple[tg.Tuple[int, int], tg.Tuple[int, int]]\n",
    "    ] = None,\n",
    ") -> tg.Tuple[tg.List[tg.Dict], tg.List[tg.Dict]]:\n",
    "    \"\"\"\n",
    "    Splits data into training and testing sets,\n",
    "    allowing for different starts and stops between\n",
    "    negative and positive classes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : tg.List[Dict]\n",
    "        the data to split\n",
    "    pos_start_stop : tg.Tuple[tg.Tuple[int, int], tg.Tuple[int, int]]\n",
    "        ((train_start, train_stop), (test_start, test_stop))\n",
    "        for positive class\n",
    "    neg_start_stop : tg.Tuple[tg.Tuple[int, int], tg.Tuple[int, int]]\n",
    "        ((train_start, train_stop), (test_start, test_stop))\n",
    "        for negative class. Optional, if None, will use the same as positive\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tg.Tuple[tg.List[Dict], tg.List[Dict]]\n",
    "        (train_data, test_data)\n",
    "    \"\"\"\n",
    "    if neg_start_stop is None:\n",
    "        neg_start_stop = pos_start_stop\n",
    "    starts_stops = (pos_start_stop, neg_start_stop)\n",
    "    train = []\n",
    "    test = []\n",
    "    for i, clx in enumerate((\"POS\", \"NEG\")):\n",
    "        print(\n",
    "            f\"Splitting data for class {clx} \\n\"\n",
    "            f\"Using train indices {starts_stops[i][0]} and \"\n",
    "            f\"test indices {starts_stops[i][1]}\"\n",
    "        )\n",
    "\n",
    "        train_idxs = range(starts_stops[i][0][0], starts_stops[i][0][1])\n",
    "        test_idxs = range(starts_stops[i][1][0], starts_stops[i][1][1])\n",
    "        train_data = [\n",
    "            data_entry\n",
    "            for data_entry in data\n",
    "            if data_entry[\"cv\"] in train_idxs and data_entry[\"sentiment\"] == clx\n",
    "        ]\n",
    "        train += train_data\n",
    "\n",
    "        test_data = [\n",
    "            data_entry\n",
    "            for data_entry in data\n",
    "            if data_entry[\"cv\"] in test_idxs and data_entry[\"sentiment\"] == clx\n",
    "        ]\n",
    "        test += test_data\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data for class POS \n",
      "Using train indices (0, 900) and test indices (900, 1000)\n",
      "Splitting data for class NEG \n",
      "Using train indices (0, 90) and test indices (900, 910)\n",
      "Accuracy: 0.891\n"
     ]
    }
   ],
   "source": [
    "pos_idxs = (0, 900, 900, 1000)\n",
    "neg_idxs = (0, 90, 900, 910)\n",
    "\n",
    "train_reviews, test_reviews = split_data(\n",
    "        lower_case_reviews,\n",
    "        (pos_idxs[:2], pos_idxs[2:]),\n",
    "        (neg_idxs[:2], neg_idxs[2:]),\n",
    ")\n",
    "\n",
    "accuracy, precision, recall, vocab_size = train_eval_nb(train_reviews, test_reviews)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6wJzcHX3WUDm"
   },
   "source": [
    "## Smoothing (1pt)\n",
    "\n",
    "As mentioned above, the presence of words in the test dataset that\n",
    "have not been seen during training can cause probabilities in the Naive\n",
    "Bayes classifier to be $0$, thus making that particular test instance\n",
    "undecidable. The standard way to mitigate this effect (as well as to\n",
    "give more clout to rare words) is to use smoothing, in which the\n",
    "probability fraction\n",
    "$$\\frac{\\text{count}(w_i, c)}{\\sum\\limits_{w\\in V} \\text{count}(w, c)}$$ for a word\n",
    "$w_i$ becomes\n",
    "$$\\frac{\\text{count}(w_i, c) + \\text{smoothing}(w_i)}{\\sum\\limits_{w\\in V} \\text{count}(w, c) + \\sum\\limits_{w \\in V} \\text{smoothing}(w)}$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBNIcbwUWphC"
   },
   "source": [
    "#### (Q2.4) Implement Laplace feature smoothing (1pt)\n",
    "Implement Laplace smoothing, i.e., smoothing with a constant value ($smoothing(w) = \\kappa, \\forall w \\in V$), in your Naive\n",
    "Bayes classifier’s code, and report the impact on performance. \n",
    "Use $\\kappa = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "g03yflCc9kpW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data for class POS \n",
      "Using train indices (0, 900) and test indices (900, 1000)\n",
      "Splitting data for class NEG \n",
      "Using train indices (0, 900) and test indices (900, 1000)\n",
      "Accuracy: 0.825\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# Laplace smoothing is already available in our implementation above, we just\n",
    "# need to pass an argument of alpha=1 when training:\n",
    "train_reviews, test_reviews = split_data(\n",
    "    lower_case_reviews,\n",
    "    (pos_idxs[:2], pos_idxs[2:]),\n",
    ")\n",
    "accuracy, precision, recall, vocab_size = train_eval_nb(train_reviews, test_reviews, 1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZiGcgwba87D5"
   },
   "source": [
    "## Cross-Validation (1.5pts)\n",
    "\n",
    "A serious danger in using Machine Learning on small datasets, with many\n",
    "iterations of slightly different versions of the algorithms, is ending up with Type III errors, also called the “testing hypotheses\n",
    "suggested by the data” errors. This type of error occurs when we make\n",
    "repeated improvements to our classifiers by playing with features and\n",
    "their processing, but we don’t get a fresh, never-before seen test\n",
    "dataset every time. Thus, we risk developing a classifier that gets better\n",
    "and better on our data, but only gets worse at generalizing to new, unseen data. In other words, we risk developping a classifier that overfits.\n",
    "\n",
    "A simple method to guard against Type III errors is to use\n",
    "Cross-Validation. In **N-fold Cross-Validation**, we divide the data into N\n",
    "distinct chunks, or folds. Then, we repeat the experiment N times: each\n",
    "time holding out one of the folds for testing, training our classifier\n",
    "on the remaining N - 1 data folds, and reporting performance on the\n",
    "held-out fold. We can use different strategies for dividing the data:\n",
    "\n",
    "-   Consecutive splitting:\n",
    "  - cv000–cv099 = Split 1\n",
    "  - cv100–cv199 = Split 2\n",
    "  - etc.\n",
    "  \n",
    "-   Round-robin splitting (mod 10):\n",
    "  - cv000, cv010, cv020, … = Split 1\n",
    "  - cv001, cv011, cv021, … = Split 2\n",
    "  - etc.\n",
    "\n",
    "-   Random sampling/splitting\n",
    "  - Not used here (but you may choose to split this way in a non-educational situation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OeLcbSauGtR"
   },
   "source": [
    "#### (Q2.5) Write the code to implement 10-fold cross-validation using round-robin splitting for your Naive Bayes classifier from Q2.4 and compute the 10 accuracies. Report the final performance, which is the average of the performances per fold. If all splits perform equally well, this is a good sign. (1pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "3KeCGPa7Nuzx"
   },
   "outputs": [],
   "source": [
    "def rr_cv_split(\n",
    "    data_len: int,\n",
    "    n_splits: int,\n",
    "    modulo: int,\n",
    "    alpha: float = 0,\n",
    ") -> tg.Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Performs round robin cross validation split\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_len : int\n",
    "        the length of the data\n",
    "    n_splits : int\n",
    "        the number of splits\n",
    "    modulo : int\n",
    "        the modulo to use for round robin splitting\n",
    "    alpha : float, default 0\n",
    "        the smoothing parameter, which is added to word counts\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of ndarray\n",
    "        tuple containing two (n_splits, -1) ndarrays\n",
    "        the first containing the indices of the training splits\n",
    "        and the second containing the indices of the test splits\n",
    "    \"\"\"\n",
    "\n",
    "    base_split: np.ndarray = np.arange(0, (data_len - n_splits) + 1, modulo)\n",
    "    splits: tg.List[np.ndarray] = [base_split + i for i in range(n_splits)]\n",
    "\n",
    "    train_splits = np.zeros((n_splits, len(base_split) * (n_splits - 1)))\n",
    "    test_splits = np.zeros((n_splits, len(base_split)))\n",
    "\n",
    "    for i, test_data_idxs in enumerate(splits):\n",
    "        train_splits[i] = np.concatenate(splits[:i] + splits[(i + 1) :])  # noqa:E203\n",
    "        test_splits[i] = test_data_idxs\n",
    "\n",
    "    return train_splits, test_splits\n",
    "\n",
    "def perform_rr_cv_nb(\n",
    "    data: tg.List[tg.Dict],\n",
    "    n_splits: int,\n",
    "    modulo: int,\n",
    "    alpha: float = 0,\n",
    "    data_len: tg.Optional[int] = None,\n",
    "    verbose: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs round robin cross validation of a naive bayes model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : tg.List[tg.Dict]\n",
    "        the data to use for training and testing\n",
    "    n_splits : int\n",
    "        the number of splits to perform\n",
    "    modulo : int\n",
    "        the modulo to use for round robin splitting\n",
    "    alpha : float, default 0\n",
    "        smoothing parameter, which is added to word counts.\n",
    "    data_len : int, default None\n",
    "        The length of the data to split. If not provided\n",
    "        is inferred from the data\n",
    "    verbose: bool, default True\n",
    "        Whether to print diagnostics\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    metrics : np.ndarray\n",
    "        (4, n_splits) array of accuracies, precisions, recalls and vocab sizes\n",
    "    \"\"\"\n",
    "    if data_len is None:\n",
    "        data_len = len(data)\n",
    "\n",
    "    train, test = rr_cv_split(data_len, n_splits, modulo)\n",
    "\n",
    "    metrics = np.zeros((4, n_splits), dtype=float)\n",
    "\n",
    "    for i, (train_idxs, test_idxs) in enumerate(zip(train, test)):\n",
    "        if verbose:\n",
    "            print(f\"Cross validating on split {i+1} of {n_splits}\")\n",
    "\n",
    "        train_data = [\n",
    "            data_entry for data_entry in data if data_entry[\"cv\"] in train_idxs\n",
    "        ]\n",
    "        test_data = [data_entry for data_entry in data if data_entry[\"cv\"] in test_idxs]\n",
    "\n",
    "        metrics[:, i] = train_eval_nb(train_data, test_data, alpha)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Cross validation complete.\")\n",
    "\n",
    "    return metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating on split 1 of 10\n",
      "Cross validating on split 2 of 10\n",
      "Cross validating on split 3 of 10\n",
      "Cross validating on split 4 of 10\n",
      "Cross validating on split 5 of 10\n",
      "Cross validating on split 6 of 10\n",
      "Cross validating on split 7 of 10\n",
      "Cross validating on split 8 of 10\n",
      "Cross validating on split 9 of 10\n",
      "Cross validating on split 10 of 10\n",
      "Cross validation complete.\n"
     ]
    }
   ],
   "source": [
    "smooth_metrics = perform_rr_cv_nb(lower_case_reviews, 10, 10, 1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV accuracies: [0.79  0.835 0.805 0.825 0.78  0.845 0.83  0.775 0.83  0.84 ]\n",
      "mean CV accuracy: 0.815\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nCV accuracies: {smooth_metrics[0]}\")\n",
    "print(f\"mean CV accuracy: {smooth_metrics[0].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otdlsDXBNyOa"
   },
   "source": [
    "#### (Q2.6) Report the variance of the 10 accuracy scores. (0.5pt)\n",
    "\n",
    "**Please report all future results using 10-fold cross-validation now\n",
    "(unless told to use the held-out test set).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ZoBQm1KuNzNR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy variance: 0.000602\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "print(f\"CV accuracy variance: {smooth_metrics[0].var():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6A2zX9_BRKm"
   },
   "source": [
    "## Features, overfitting, and the curse of dimensionality\n",
    "\n",
    "In the Bag-of-Words model, ideally we would like each distinct word in\n",
    "the text to be mapped to its own dimension in the output vector\n",
    "representation. However, real world text is messy, and we need to decide\n",
    "on what we consider to be a word. For example, is “`word`\" different\n",
    "from “`Word`\", from “`word`”, or from “`words`\"? Too strict a\n",
    "definition, and the number of features explodes, while our algorithm\n",
    "fails to learn anything generalisable. Too lax, and we risk destroying\n",
    "our learning signal. In the following section, you will learn about\n",
    "confronting the feature sparsity and the overfitting problems as they\n",
    "occur in NLP classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKK8FNt8VtcZ"
   },
   "source": [
    "### Stemming (1.5pts)\n",
    "\n",
    "To make your algorithm more robust, use stemming and hash different inflections of a word to the same feature in the BoW vector space. Please use the [Porter stemming\n",
    "    algorithm](http://www.nltk.org/howto/stem.html) from NLTK.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "NxtCul1IrBi_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming requested; stemming...\n",
      "Stemming complete.\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "stemmed_reviews = preprocess_reviews(reviews, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SrJ1BeLXTnk"
   },
   "source": [
    "#### (Q2.7): How does the performance of your classifier change when you use stemming on your training and test datasets? (1pt)\n",
    "Use cross-validation to evaluate the classifier. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "gYqKBOiIrInT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating on split 1 of 10\n",
      "Cross validating on split 2 of 10\n",
      "Cross validating on split 3 of 10\n",
      "Cross validating on split 4 of 10\n",
      "Cross validating on split 5 of 10\n",
      "Cross validating on split 6 of 10\n",
      "Cross validating on split 7 of 10\n",
      "Cross validating on split 8 of 10\n",
      "Cross validating on split 9 of 10\n",
      "Cross validating on split 10 of 10\n",
      "Cross validation complete.\n"
     ]
    }
   ],
   "source": [
    "stem_metrics = perform_rr_cv_nb(stemmed_reviews, 10, 10, 1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracies: [0.785 0.84  0.805 0.835 0.77  0.845 0.82  0.775 0.825 0.83 ]\n",
      "mean CV accuracy: 0.813\n",
      "CV accuracy variance: 0.000686\n"
     ]
    }
   ],
   "source": [
    "print(f\"CV accuracies: {stem_metrics[0]}\")\n",
    "print(f\"mean CV accuracy: {stem_metrics[0].mean():.3f}\")\n",
    "print(f\"CV accuracy variance: {stem_metrics[0].var():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy decreases when using stemming, while the variance increases. Both these changes are marginal and potentially negligible with respect to the values obtained in 2.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkDHVq_1XUVP"
   },
   "source": [
    "#### (Q2.8) What happens to the number of features (i.e., the size of the vocabulary) when using stemming as opposed to (Q2.4)? (0.5pt)\n",
    "Give actual numbers. You can use the held-out training set to determine these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "MA3vee5-rJyy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average vocab size without stemming: 45446.50\n",
      "Average vocab size with stemming: 32680.20\n",
      "percentage change: -28.09 %\n"
     ]
    }
   ],
   "source": [
    "mean_vocab_size = smooth_metrics[-1].mean()\n",
    "mean_stem_vocab_size = stem_metrics[-1].mean()\n",
    "percentage_change = (\n",
    "    (-1 if mean_stem_vocab_size < mean_vocab_size else 1)\n",
    "    * np.abs(mean_vocab_size - mean_stem_vocab_size)\n",
    "    / mean_vocab_size\n",
    ") * 100\n",
    "\n",
    "\n",
    "print(f\"Average vocab size without stemming: {mean_vocab_size:.2f}\")\n",
    "print(f\"Average vocab size with stemming: {mean_stem_vocab_size:.2f}\")\n",
    "print(f\"percentage change: {percentage_change:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of features decreases when using stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoazfxbNV5Lq"
   },
   "source": [
    "### N-grams (1.5pts)\n",
    "\n",
    "A simple way of retaining some of the word\n",
    "order information when using bag-of-words representations is to use **n-gram** features. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHjy3I7-qWiu"
   },
   "source": [
    "#### (Q2.9) Retrain your classifier from (Q2.4) using **unigrams+bigrams** and **unigrams+bigrams+trigrams** as features. (1pt)\n",
    "Report accuracy and compare it with that of the approaches you have previously implemented. You are allowed to use NLTK to build n-grams from sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "eYuKMTOpq9jz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ngrams...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "bigrammed_reviews = preprocess_reviews(\n",
    "    lower_case_reviews, stem=False, bigrams=True, trigrams=False, cached=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ngrams...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "trigrammed_reviews = preprocess_reviews(\n",
    "    lower_case_reviews, stem=False, bigrams=True, trigrams=True, cached=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating on split 1 of 10\n",
      "Cross validating on split 2 of 10\n",
      "Cross validating on split 3 of 10\n",
      "Cross validating on split 4 of 10\n",
      "Cross validating on split 5 of 10\n",
      "Cross validating on split 6 of 10\n",
      "Cross validating on split 7 of 10\n",
      "Cross validating on split 8 of 10\n",
      "Cross validating on split 9 of 10\n",
      "Cross validating on split 10 of 10\n",
      "Cross validation complete.\n"
     ]
    }
   ],
   "source": [
    "bigram_metrics = perform_rr_cv_nb(\n",
    "    bigrammed_reviews, 10, 10, 1, 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating on split 1 of 10\n",
      "Cross validating on split 2 of 10\n",
      "Cross validating on split 3 of 10\n",
      "Cross validating on split 4 of 10\n",
      "Cross validating on split 5 of 10\n",
      "Cross validating on split 6 of 10\n",
      "Cross validating on split 7 of 10\n",
      "Cross validating on split 8 of 10\n",
      "Cross validating on split 9 of 10\n",
      "Cross validating on split 10 of 10\n",
      "Cross validation complete.\n"
     ]
    }
   ],
   "source": [
    "trigram_metrics = perform_rr_cv_nb(\n",
    "    trigrammed_reviews, 10, 10, 1, 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV unigram+bigram accuracies: [0.795 0.85  0.84  0.875 0.81  0.86  0.83  0.83  0.845 0.835]\n",
      "mean CV unigram+bigram accuracy: 0.837\n",
      "CV unigram+bigram accuracy variance: 0.000481\n",
      "-----------------------------------\n",
      "CV unigram+bigram+trigram accuracies: [0.79  0.85  0.835 0.86  0.82  0.85  0.85  0.84  0.85  0.805]\n",
      "mean CV unigram+bigram+trigram accuracy: 0.835\n",
      "CV unigram+bigram+trigram accuracy variance: 0.000470\n"
     ]
    }
   ],
   "source": [
    "print(f\"CV unigram+bigram accuracies: {bigram_metrics[0]}\")\n",
    "print(f\"mean CV unigram+bigram accuracy: {bigram_metrics[0].mean():.3f}\")\n",
    "print(f\"CV unigram+bigram accuracy variance: {bigram_metrics[0].var():.6f}\")\n",
    "print(\"-----------------------------------\")\n",
    "print(f\"CV unigram+bigram+trigram accuracies: {trigram_metrics[0]}\")\n",
    "print(f\"mean CV unigram+bigram+trigram accuracy: {trigram_metrics[0].mean():.3f}\")\n",
    "print(f\"CV unigram+bigram+trigram accuracy variance: {trigram_metrics[0].var():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Table 1**: Comparison of Mean Accuracy and Accuracy Variance across various portions of the experiment. `u` refers to \"unigrams\", `b` to 'bigrams', and `t` to 'trigram'.\n",
    "\n",
    "|          | u smoothing (2.5) | u stemming (2.7) | u + b    | u + b + t |\n",
    "|----------|-------------------|------------------|----------|-----------|\n",
    "| Accuracy | 0.815             | 0.813            | 0.837    | 0.835     |\n",
    "| Variance | 0.000602          | 0.000685         | 0.000481 | 0.000470  |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVrGGArkrWoL"
   },
   "source": [
    "\n",
    "#### Q2.10: How many features does the BoW model have to take into account now? (0.5pt)\n",
    "How would you expect the number of features to increase theoretically (e.g., linear, square, cubed, exponential)? How does this number compare, in practice, to the number of features at (Q2.8)?\n",
    "\n",
    "Use the held-out training set once again for this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEGZ9SV8pPaa"
   },
   "source": [
    "---\n",
    "\n",
    "I would expect the number of features to increase squared $O(n + n^2)= O(n^2)$ when using bigrams and cubed $O(n + n^2 + n^3)= O(n^3)$ when using trigrams. In other words, exponentially with the number of items $k$ in largest order n-gram $O(n^k)$ used. This is of course a \"worst-case\" scenario, as this kind of increase would only occur if all possible n-gram combinations were available given our set of unigrams, i.e. if our reviews were very dense. In practice, because of the sparsity of language, the number of features seems to increase linearly instead, as seen by the numbers below (ignoring stemming).\n",
    "\n",
    "With stemming, the number of features decreases as words with identical stems but different affixes are \"compressed\" into a single feature, i.e. the stem.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "_z8sAJeUrdtM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data for class POS \n",
      "Using train indices (0, 900) and test indices (900, 1000)\n",
      "Splitting data for class NEG \n",
      "Using train indices (0, 900) and test indices (900, 1000)\n",
      "Splitting data for class POS \n",
      "Using train indices (0, 900) and test indices (900, 1000)\n",
      "Splitting data for class NEG \n",
      "Using train indices (0, 900) and test indices (900, 1000)\n",
      "Splitting data for class POS \n",
      "Using train indices (0, 900) and test indices (900, 1000)\n",
      "Splitting data for class NEG \n",
      "Using train indices (0, 900) and test indices (900, 1000)\n",
      "Splitting data for class POS \n",
      "Using train indices (0, 900) and test indices (900, 1000)\n",
      "Splitting data for class NEG \n",
      "Using train indices (0, 900) and test indices (900, 1000)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "train_reviews, test_reviews = split_data(\n",
    "    lower_case_reviews,\n",
    "    (pos_idxs[:2], pos_idxs[2:]),\n",
    ")\n",
    "stem_train_reviews, _stem_test_reviews = split_data(\n",
    "    stemmed_reviews,\n",
    "    (pos_idxs[:2], pos_idxs[2:]),\n",
    ")\n",
    "bi_train_reviews, _bi_test_reviews = split_data(\n",
    "    bigrammed_reviews,\n",
    "    (pos_idxs[:2], pos_idxs[2:]),\n",
    ")\n",
    "tri_train_reviews, _tri_test_reviews = split_data(\n",
    "    trigrammed_reviews,\n",
    "    (pos_idxs[:2], pos_idxs[2:]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_vocab, _np, _nl = train_nb((\"POS\", \"NEG\"), train_reviews, alpha=1)\n",
    "stem_vocab, _sp, _sl = train_nb((\"POS\", \"NEG\"), stem_train_reviews, alpha=1)\n",
    "bi_vocab, _bp, _bl = train_nb((\"POS\", \"NEG\"), bi_train_reviews, alpha=1)\n",
    "tri_vocab, _tp, _tl = train_nb((\"POS\", \"NEG\"), tri_train_reviews, alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-stemmed (2.4) number of features: 45348\n",
      "Stemmed (2.8) number of features: 32561\n",
      "unigram+bigram number of features: 471032\n",
      "unigram+bigram+trigram number of features: 1416686\n"
     ]
    }
   ],
   "source": [
    "print(f\"non-stemmed (2.4) number of features: {len(smooth_vocab.items())}\")\n",
    "print(f\"Stemmed (2.8) number of features: {len(stem_vocab.items())}\")\n",
    "print(f\"unigram+bigram number of features: {len(bi_vocab.items())}\") \n",
    "print(f\"unigram+bigram+trigram number of features: {len(tri_vocab.items())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHWKDL3YV6vh"
   },
   "source": [
    "# Support Vector Machines (4pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJSYhcVaoJGt"
   },
   "source": [
    "Though simple to understand, implement, and debug, one\n",
    "major problem with the Naive Bayes classifier is that its performance\n",
    "deteriorates (becomes skewed) when it is being used with features which\n",
    "are not independent (i.e., are correlated). Another popular classifier\n",
    "that doesn’t scale as well to big data, and is not as simple to debug as\n",
    "Naive Bayes, but that doesn’t assume feature independence is the Support\n",
    "Vector Machine (SVM) classifier.\n",
    "\n",
    "You can find more details about SVMs in Chapter 7 of Bishop: Pattern Recognition and Machine Learning.\n",
    "Other sources for learning SVM:\n",
    "* http://web.mit.edu/zoya/www/SVM.pdf\n",
    "* http://www.cs.columbia.edu/~kathy/cs4701/documents/jason_svm_tutorial.pdf\n",
    "* https://pythonprogramming.net/support-vector-machine-intro-machine-learning-tutorial/\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Use the scikit-learn implementation of \n",
    "[SVM](http://scikit-learn.org/stable/modules/svm.html) with the default parameters. (You are not expected to perform any hyperparameter tuning, but feel free to do it if you think it gives you good insights for the discussion in question 5.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LnzNtQBV8gr"
   },
   "source": [
    "#### (Q3.1): Train SVM and compare to Naive Bayes (2pts)\n",
    "\n",
    "Train an SVM classifier (sklearn.svm.LinearSVC) using the features collected for Naive Bayes. Compare the\n",
    "classification performance of the SVM classifier to that of the Naive\n",
    "Bayes classifier with smoothing.\n",
    "Use cross-validation to evaluate the performance of the classifiers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "JBscui8Mvoz0"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "POS_MAP = {\n",
    "    \"JJ\": \"adj\",\n",
    "    \"JJR\": \"adj\",\n",
    "    \"JJS\": \"adj\",\n",
    "    \"RB\": \"adverb\",\n",
    "    \"RBR\": \"adverb\",\n",
    "    \"RBS\": \"adverb\",\n",
    "    \"NN\": \"noun\",\n",
    "    \"NNS\": \"noun\",\n",
    "    \"NNP\": \"noun\",\n",
    "    \"NNPS\": \"noun\",\n",
    "    \"VB\": \"verb\",\n",
    "    \"VBD\": \"verb\",\n",
    "    \"VBG\": \"verb\",\n",
    "    \"VBN\": \"verb\",\n",
    "    \"VBP\": \"verb\",\n",
    "    \"VBZ\": \"verb\",\n",
    "    \"WRB\": \"adverb\",\n",
    "}\n",
    "\n",
    "\n",
    "def encode_reviews(\n",
    "    reviews: tg.List[tg.Dict],\n",
    "    codeword_map: tg.Dict,\n",
    "    use_pos: bool = False,\n",
    ") -> tg.Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Encode reviews into a features matrix and labels vector.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    reviews : tg.List[tg.Dict]\n",
    "        List of reviews to encode\n",
    "    codeword_map: tg.Dict\n",
    "        Map of codewords to indices\n",
    "    use_pos: bool, default False\n",
    "        Whether codeword_map uses word+POS as keys\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    feature_mat : np.ndarray\n",
    "        A matrix of features, where each row represents\n",
    "        a review and each column represents the count of\n",
    "        a given word from our vocab in that review.\n",
    "    label_vec : np.ndarray\n",
    "        A vector of labels, where each element is either\n",
    "        0 or 1, representing the sentiment (POS or NEG) of the review.\n",
    "    \"\"\"\n",
    "    feature_mat = np.zeros((len(reviews), len(codeword_map)))\n",
    "    label_vec = np.zeros(len(reviews))\n",
    "\n",
    "    for i, review in enumerate(reviews):\n",
    "        label_vec[i] = SENT_MAP[review[\"sentiment\"]]\n",
    "        for sentence in review[\"content\"]:\n",
    "            for token, pos in sentence:\n",
    "                if use_pos:\n",
    "                    key = (token, pos)\n",
    "                else:\n",
    "                    key = token\n",
    "                if key in codeword_map:\n",
    "                    feature_mat[i, codeword_map[key]] += 1\n",
    "\n",
    "    return feature_mat, label_vec\n",
    "\n",
    "\n",
    "def perform_rr_cv_svm(\n",
    "    data: tg.List[tg.Dict],\n",
    "    n_splits: int,\n",
    "    modulo: int,\n",
    "    data_len: tg.Optional[int] = None,\n",
    "    use_pos: bool = False,\n",
    "    only_open: bool = False,\n",
    "    std: bool = True,\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs round robin cross validation of the SVM model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : tg.List[tg.Dict]\n",
    "        List of reviews to perform cross validation on\n",
    "    n_splits : int\n",
    "        Number of splits to perform\n",
    "    modulo : int\n",
    "        the modulo to use for round robin splitting\n",
    "    data_len : tg.Optional[int]\n",
    "        Length of data to use for splitting, if None\n",
    "        will be inferred from data\n",
    "    use_pos: bool, default False\n",
    "        Whether to use word+POS as keys\n",
    "    only_open: bool, default False\n",
    "        Whether to use only open-class POS words\n",
    "    std: bool, default True\n",
    "        Whether to standardize the data before training\n",
    "    verbose : bool, default True\n",
    "        Whether to print out diagnostics\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    metrics : np.ndarray\n",
    "        (4, n_splits) array of accuracies, precisions, recalls and vocab_sizes\n",
    "    \"\"\"\n",
    "\n",
    "    if data_len is None:\n",
    "        data_len = len(data)\n",
    "\n",
    "    train, test = rr_cv_split(data_len, n_splits, modulo)\n",
    "\n",
    "    metrics = np.zeros((4, n_splits), dtype=float)\n",
    "\n",
    "    for i, (train_idxs, test_idxs) in enumerate(zip(train, test)):\n",
    "        if verbose:\n",
    "            print(f\"Cross validating on split {i+1} of {n_splits}\")\n",
    "\n",
    "        train_data = [\n",
    "            data_entry for data_entry in data if data_entry[\"cv\"] in train_idxs\n",
    "        ]\n",
    "        test_data = [data_entry for data_entry in data if data_entry[\"cv\"] in test_idxs]\n",
    "\n",
    "        metrics[:, i] = train_eval_svm(train_data, test_data, use_pos, only_open, std)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Cross validation complete.\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def train_eval_svm(\n",
    "    train_data: tg.List[tg.Dict],\n",
    "    test_data: tg.List[tg.Dict],\n",
    "    use_pos: bool = False,\n",
    "    only_open: bool = False,\n",
    "    std: bool = True,\n",
    ") -> tg.Tuple[float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Trains and evaluates the SVM model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data : tg.List[tg.Dict]\n",
    "        the training data\n",
    "    test_data : tg.List[tg.Dict]\n",
    "        the testing data\n",
    "    use_pos: bool, default False\n",
    "        Whether to use word+POS as keys\n",
    "    only_open: bool, default False\n",
    "        Whether to use only open-class POS words\n",
    "    std: bool, default True\n",
    "        Whether to standardize the data before training\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    metrics : tuple of floats\n",
    "        tuple of accuracy, precision, recall and vocab size\n",
    "\n",
    "    \"\"\"\n",
    "    vocab = extract_vocab(train_data, use_pos, only_open)\n",
    "    codeword_map = {key: idx for idx, key in enumerate(vocab.keys())}\n",
    "    train_X, train_y = encode_reviews(train_data, codeword_map, use_pos)\n",
    "    test_X, test_y = encode_reviews(test_data, codeword_map, use_pos)\n",
    "\n",
    "    if std:\n",
    "        clf = make_pipeline(StandardScaler(with_mean=False), LinearSVC(max_iter=10000))\n",
    "    else:\n",
    "        clf = LinearSVC(max_iter=10000)\n",
    "\n",
    "    clf.fit(csr_matrix(train_X), train_y)\n",
    "\n",
    "    preds = clf.predict(csr_matrix(test_X))\n",
    "\n",
    "    accuracy = accuracy_score(test_y, preds)\n",
    "    precision = precision_score(test_y, preds)\n",
    "    recall = recall_score(test_y, preds)\n",
    "    vocab_size = len(vocab.keys())\n",
    "\n",
    "    return accuracy, precision, recall, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating on split 1 of 10\n",
      "Cross validating on split 2 of 10\n",
      "Cross validating on split 3 of 10\n",
      "Cross validating on split 4 of 10\n",
      "Cross validating on split 5 of 10\n",
      "Cross validating on split 6 of 10\n",
      "Cross validating on split 7 of 10\n",
      "Cross validating on split 8 of 10\n",
      "Cross validating on split 9 of 10\n",
      "Cross validating on split 10 of 10\n",
      "Cross validation complete.\n"
     ]
    }
   ],
   "source": [
    "svm_metrics = perform_rr_cv_svm(\n",
    "    lower_case_reviews, 10, 10, 1000, False, False, False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracies: [0.81  0.795 0.8   0.84  0.85  0.815 0.845 0.85  0.875 0.84 ]\n",
      "mean CV accuracy: 0.8320000000000001\n",
      "CV accuracy variance: 0.0005959999999999991\n"
     ]
    }
   ],
   "source": [
    "print(f\"CV accuracies: {svm_metrics[0]}\")\n",
    "print(f\"mean CV accuracy: {svm_metrics[0].mean()}\")\n",
    "print(f\"CV accuracy variance: {svm_metrics[0].var()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifXVWcK0V9qY"
   },
   "source": [
    "### POS disambiguation (2pts)\n",
    "\n",
    "Now add in part-of-speech features. You will find the\n",
    "movie review dataset has already been POS-tagged for you ([here](https://catalog.ldc.upenn.edu/docs/LDC99T42/tagguid1.pdf) you find the tagset). Try to\n",
    "replicate the results obtained by Pang et al. (2002).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xA3I82o4oWGu"
   },
   "source": [
    "#### (Q3.2) Replace your features with word+POS features, and report performance with the SVM. Use cross-validation to evaluate the classifier and compare the results with (Q3.1). Does part-of-speech information help? Explain why this may be the case. (1pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "NOvjYe-t2Br6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating on split 1 of 10\n",
      "Cross validating on split 2 of 10\n",
      "Cross validating on split 3 of 10\n",
      "Cross validating on split 4 of 10\n",
      "Cross validating on split 5 of 10\n",
      "Cross validating on split 6 of 10\n",
      "Cross validating on split 7 of 10\n",
      "Cross validating on split 8 of 10\n",
      "Cross validating on split 9 of 10\n",
      "Cross validating on split 10 of 10\n",
      "Cross validation complete.\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "svm_pos_metrics = perform_rr_cv_svm(\n",
    "    lower_case_reviews, 10, 10, 1000, True, False, False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracies: [0.82  0.795 0.825 0.84  0.84  0.845 0.855 0.855 0.865 0.84 ]\n",
      "mean CV accuracy: 0.8380000000000001\n",
      "CV accuracy variance: 0.0003709999999999997\n"
     ]
    }
   ],
   "source": [
    "print(f\"CV accuracies: {svm_pos_metrics[0]}\")\n",
    "print(f\"mean CV accuracy: {svm_pos_metrics[0].mean()}\")\n",
    "print(f\"CV accuracy variance: {svm_pos_metrics[0].var()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0dt_oQupUNe"
   },
   "source": [
    "---\n",
    "\n",
    "Part of speech information appears to help given the higher accuracy. This may be because the POS of a word carries semantic meaning, allowing us to disambiguate between words that may have negative or positive sentiments attached to them depending on their POS. For instance, \"fine\" (noun) and \"fine\" (adjective) probably have negative and positive sentiments respectively. Pairing them with their POS removes ambiguity. This disambiguation helps our model correctly weigh features in a review and improve in its classification. \n",
    "\n",
    "We note that the increase in accuracy is minimal, most likely due to this being an incomplete disambiguation approach: Based on experimentation with the lexicon above, we found that it is rare for different POS tags to b\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Su-3w87eMW0w"
   },
   "source": [
    "#### (Q3.3) Discard all closed-class words from your data (keep only nouns, verbs, adjectives, and adverbs), and report performance. Does this help? Use cross-validation to evaluate the classifier and compare the results with (Q3.2). Are closed-class words detrimental to the classifier? Explain why this may be the case. (1pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "CCUPlPozCYUX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating on split 1 of 10\n",
      "Cross validating on split 2 of 10\n",
      "Cross validating on split 3 of 10\n",
      "Cross validating on split 4 of 10\n",
      "Cross validating on split 5 of 10\n",
      "Cross validating on split 6 of 10\n",
      "Cross validating on split 7 of 10\n",
      "Cross validating on split 8 of 10\n",
      "Cross validating on split 9 of 10\n",
      "Cross validating on split 10 of 10\n",
      "Cross validation complete.\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "svm_open_pos_metrics = perform_rr_cv_svm(\n",
    "    lower_case_reviews, 10, 10, 1000, True, True, False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracies: [0.82  0.83  0.84  0.86  0.845 0.835 0.88  0.86  0.865 0.82 ]\n",
      "mean CV accuracy: 0.8455\n",
      "CV accuracy variance: 0.0003672500000000007\n"
     ]
    }
   ],
   "source": [
    "print(f\"CV accuracies: {svm_open_pos_metrics[0]}\")\n",
    "print(f\"mean CV accuracy: {svm_open_pos_metrics[0].mean()}\")\n",
    "print(f\"CV accuracy variance: {svm_open_pos_metrics[0].var()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaxCVrs8pWSp"
   },
   "source": [
    "---\n",
    "\n",
    "Given that accuracy increases when removing closed-class words, one could argue that they are detrimental to the classifier. This is probably because closed-class words carry little semantic information with regards to sentiment analysis, and as such act as noise. Think of words \"the\" or \"and\". These are very sentimentally neutral words. Removing such noise will help our model improve its accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfwqOciAl2No"
   },
   "source": [
    "# (Q4) Discussion (max. 500 words). (5pts)\n",
    "\n",
    "> Based on your experiments, what are the effective features and techniques in sentiment analysis? What information do different features encode?\n",
    "Why is this important? What are the limitations of these features and techniques?\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting non_smoothed NB metrics (verbosity turned off)\n",
    "non_smooth_metrics = perform_rr_cv_nb(lower_case_reviews, 10, 10, 0, 1000, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# quick experimentation\n",
    "sns.set_context(\"notebook\")\n",
    "metrics_dfs = []\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "axes = axes.flatten()\n",
    "for i, metric in enumerate([\"accuracy\", \"precision\", \"recall\"]):\n",
    "    metric_df = pd.DataFrame(\n",
    "        data=np.array(\n",
    "            [\n",
    "                non_smooth_metrics[i],\n",
    "                smooth_metrics[i],\n",
    "                stem_metrics[i],\n",
    "                bigram_metrics[i],\n",
    "                trigram_metrics[i],\n",
    "                svm_metrics[i],\n",
    "                svm_pos_metrics[i],\n",
    "                svm_open_pos_metrics[i],\n",
    "            ]\n",
    "        ).T,\n",
    "        columns=[\n",
    "            \"no smoothing\",\n",
    "            \"smooth (2.5)\",\n",
    "            \"stem (2.7)\",\n",
    "            \"u+b (2.9)\",\n",
    "            \"u+b+t (2.9)\",\n",
    "            \"svm (3.1)\",\n",
    "            \"svm_pos (3.2)\",\n",
    "            \"svm_open_pos (3.3)\",\n",
    "        ],\n",
    "    )\n",
    "    metrics_dfs.append(metric_df)\n",
    "    ax = axes[i]\n",
    "    sns.boxplot(data=metric_df, ax=ax)\n",
    "    ax.tick_params(axis=\"x\", rotation=45)\n",
    "    ax.set_title(f\"{metric}\")\n",
    "fig.suptitle(\n",
    "    \"Fig 2: Box plots of differenet performance metrics across various experiments in this notebook. Precision and Recall are computed w.r.t. the negative sentiment class\"\n",
    ")\n",
    "fig.set_tight_layout(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYuse5WLmekZ"
   },
   "source": [
    "---\n",
    "\n",
    "Based on our experiments, some effective features in Sentiment Analysis are\n",
    "token occurrence and parts of speech (POS) tags. The former acts as a weight\n",
    "associating a given token to a sentiment. POS tags add dimensionality to token\n",
    "occurrence, helping models to disambiguate if possible. This is important given\n",
    "the (lexical, semantic and syntactic) ambiguity that pervades languages. This is\n",
    "limited though in that often POS is not enough to disambiguate sentiment:\n",
    "consider the word \"match\" for instance, which can have several semantic meanings\n",
    "for the same POS form. Some neutral words can be dealt with by not considering closed-class POS tags,\n",
    "as was done in section 3.3.\n",
    "\n",
    "Some effective techniques that use these features are Naive Bayes (NB) and\n",
    "Support Vector Machines (SVM's). We do not consider lexicon-based approaches\n",
    "effective given their lower performance and reliance on a provided lexicon. A\n",
    "classic limitation of NB is the fact that context is lost given our independence\n",
    "assumption. What this means is that word order also does not affect our\n",
    "predictions. This may be problematic for sentiment analysis given long-distance\n",
    "dependencies often present in language. Issues with the independence assumption\n",
    "can be noticed by considering the phrases \"bad not good\" and \"good not bad\"\n",
    "which are permutations of the same set of words resulting in different\n",
    "semantics. This issue can be somewhat addressed by using n-grams rather than\n",
    "unigrams. This, however, has memory implications, with vocabulary sizes greatly\n",
    "increasing with the order of the n-grams used as discussed in 2.10. While this\n",
    "limitation is intrinsic to NB models, it is not necessarily present in SVM's.\n",
    "However, since in our approach we were simply using token occurrence (optionally\n",
    "augmented with POS tags) as features, we were implicitly incorporating this\n",
    "assumption into our SVM training, making little to no use of context.\n",
    "\n",
    "While throughout the work we utilized accuracy to evaluate our models, as\n",
    "discussed in 2.2 this is a limited metric which could be replaced by other\n",
    "metrics more suitable to the problem. For instance, from Fig. 2, when using\n",
    "accuracy, the trend appears to suggest that SVM's outperform NB models. However,\n",
    "the precision and recall metrics for these models seem to suggest that NB\n",
    "trained on n-gram combinations are better suited for problems sensitive to\n",
    "precision of classifying negative reviews, while SVMs are better suited for problems sensitive to recall. That\n",
    "being said, SVM's were not trained on n-grams and a comparison may therefore not\n",
    "be fair. Future work could consider training SVM's with n-gram features, or\n",
    "exploring models with better context management.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwaKwfWQhRk_"
   },
   "source": [
    "# Submission \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "aOUeaET5ijk-"
   },
   "outputs": [],
   "source": [
    "# Write your names and student numbers here:\n",
    "# Giulio Starace # 13010840\n",
    "# Luuk Verheijen # 11331704"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3A9K-H6Tii3X"
   },
   "source": [
    "**That's it!**\n",
    "\n",
    "- Check if you answered all questions fully and correctly. \n",
    "- Download your completed notebook using `File -> Download .ipynb` \n",
    "- Check if your answers are all included in the file you submit.\n",
    "- Submit your .ipynb file via *Canvas*. One submission per group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHslatYAKBrF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "practical1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
